Korinek’s paper highlights six core areas where large language models (LLMs) like ChatGPT can support researchers: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. Generative AI tools have matured into practical resources for automating “micro-tasks”—small, repetitive steps that accumulate significantly throughout research. Automating these tasks can result in substantial productivity gains.

In my research on developing a two-dimensional Fama-French factor portfolio for Indian equities, I see LLMs like ChatGPT helping me streamline my workflow, particularly in drafting, debugging Python scripts, and verifying methodologies. Recently, I used ChatGPT to troubleshoot Python scripts for my Jupyter Notebook, where the rapid iteration enabled me to make efficient progress without extra resources or excessive time.

Korinek emphasizes LLMs' effectiveness in automating repetitive, low-scale tasks that are usually impractical for human research assistants. The productivity benefits I’ve experienced align with his observations, especially when minor coding issues, like syntax or logical errors, stall my work. By resolving these quickly with ChatGPT, I can stay focused on higher-level analysis and more strategic parts of my research.

That said, as Korinek warns, using AI tools in sensitive research areas brings risks, especially regarding data privacy and model accuracy. Since my research involves proprietary financial metrics, I am cautious about entering any specific data or sensitive methodologies into LLMs, mindful of potential retention and future model training. Instead, I use LLMs for general debugging or broader questions, never entering confidential details.

Balancing reliance on AI while remaining vigilant about its limitations is key. LLMs can occasionally produce plausible yet incorrect responses, and Korinek advises against over-reliance or complete dismissal. I treat LLM outputs as starting points, applying my judgment to assess their validity before using them.

Overall, incorporating LLMs into my research has enhanced my workflow, but doing so requires a mindful approach. By automating low-level tasks, these tools have freed me to focus on critical analysis while highlighting the importance of using AI cautiously in sensitive contexts.
